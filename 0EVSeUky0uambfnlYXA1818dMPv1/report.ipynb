{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%logstop\n",
    "%logstart -t -r -q ipython_command_log.py global\n",
    "\n",
    "#- IRONHACKS RESEARCH TRACKING CODE\n",
    "#----------------------------------\n",
    "# The following code is used to help our research team understand how you \n",
    "# our notebook environment. We do not collect any personal information with\n",
    "# the following code, it is used to measure when and how often you work on\n",
    "# your submission files.\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import IPython.core.history as history\n",
    "\n",
    "ha = history.HistoryAccessor()\n",
    "ha_tail = ha.get_tail(1)\n",
    "ha_cmd = next(ha_tail)\n",
    "session_id = str(ha_cmd[0])\n",
    "command_id = str(ha_cmd[1])\n",
    "timestamp = datetime.utcnow().isoformat()\n",
    "history_line = ','.join([session_id, command_id, timestamp]) + '\\n'\n",
    "logfile = open(os.environ['HOME']+'/ipython_session_log.csv', 'a')\n",
    "logfile.write(history_line)\n",
    "logfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mpld3\n",
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import requests\n",
    "import random\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery import magics\n",
    "from ipywidgets import *\n",
    "from ipyleaflet import *\n",
    "import pyarrow\n",
    "\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap, HeatMapWithTime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mpld3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIGQUERY_PROJECT = 'ironhacks-covid19-data'\n",
    "BIGQUERY_KEYPATH = '../service-account.json'\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = BIGQUERY_KEYPATH\n",
    "bigquery_client = bigquery.Client(project=BIGQUERY_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT poi_id, poi_cbg, location_name, week_number, date_start, raw_visit_counts, visits_concentration, distance_from_home, median_dwell\n",
    "FROM ironhacks_covid19_competition.weekly_patterns;\n",
    "\"\"\"\n",
    "\n",
    "query_job = bigquery_client.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_lists_query = \"\"\"\n",
    "SELECT *\n",
    "FROM ironhacks_covid19_competition.prediction_list_poi\n",
    "\"\"\"\n",
    "\n",
    "query_job_poi = bigquery_client.query(poi_lists_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_list = query_job_poi.to_dataframe()\n",
    "weekly_patterns = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima(poi_id):\n",
    "    data = weekly_patterns[weekly_patterns['poi_id'] == poi_id].sort_values(by='week_number')\n",
    "    \n",
    "    model = ARIMA(data['raw_visit_counts'].values, order=(1,0,0))\n",
    "    fitted = model.fit()\n",
    "    \n",
    "    forecast = fitted.forecast(steps=1)[0]\n",
    "    data = data[['week_number', 'raw_visit_counts']]\n",
    "    \n",
    "    return data, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_fig_to_html(fig):\n",
    "    \"\"\" Convert Matplotlib figure 'fig' into a <img> tag for HTML use using base64 encoding. \"\"\"\n",
    "    import urllib\n",
    "    from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "    import StringIO\n",
    "\n",
    "    canvas = FigureCanvas(fig)\n",
    "    png_output = StringIO.StringIO()\n",
    "    canvas.print_png(png_output)\n",
    "    data = png_output.getvalue().encode('base64')\n",
    "\n",
    "    return '<img src=\"data:image/png;base64,{}\">'.format(urllib.quote(data.rstrip('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = weekly_patterns['poi_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling time series data using Autoregression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "forecasts = []\n",
    "\n",
    "print(\"Modelling started\")\n",
    "\n",
    "for idx, location in enumerate(locations):\n",
    "    try:\n",
    "        d, forecast = arima(location)\n",
    "        data.append(d)\n",
    "        forecasts.append(forecast)\n",
    "\n",
    "        if idx % 500 == 0:\n",
    "            print(\"Finished modelling {}/1804 locations\".format(idx))\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving top 50 busiest POIs from the predicted values\n",
    "\n",
    "forecasts_ = forecasts\n",
    "data_50 = []\n",
    "forecasts_50 = []\n",
    "locations_50 = []\n",
    "\n",
    "for f in sorted(forecasts_, reverse=True)[:50]:\n",
    "    forecasts_50.append(f)\n",
    "    data_50.append(data[forecasts_.index(f)])\n",
    "    loc = weekly_patterns.loc[weekly_patterns['poi_id'] == locations[forecasts_.index(f)]]['location_name'].unique()[0]\n",
    "    locations_50.append(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting top 50 busiest POIs\n",
    "\n",
    "fig, axes = plt.subplots(10,5, figsize=(26,13))\n",
    "\n",
    "for ax, datum, forecast, location in zip(axes.flatten(), data_50, forecasts_50, locations_50):\n",
    "    ax.plot(datum['week_number'], datum['raw_visit_counts'], label=\"Historic data\")\n",
    "    ax.plot(44, forecast, 'o', label=\"Forecast for week 44\")\n",
    "    ax.set_title(location)\n",
    "\n",
    "fig.text(0.5, -0.04, 'Week number', ha='center', fontsize=20)\n",
    "fig.text(-0.02, 0.5, 'Visit counts', va='center', rotation='vertical', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.legend(bbox_to_anchor=(2.1, 1.5))\n",
    "\n",
    "plt.savefig('visit_counts_viz.png', dpi=300, bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating general statistics like average visit concentration and median dwell time\n",
    "\n",
    "concs, dists, dwells = [], [], []\n",
    "\n",
    "for week in weekly_patterns['week_number'].unique():\n",
    "    temp = weekly_patterns[weekly_patterns['week_number'] == week]\n",
    "    concs.append(temp['visits_concentration'].mean())\n",
    "    dists.append(temp['distance_from_home'].mean())\n",
    "    dwells.append(temp['median_dwell'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting general statistics\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "axes[0].plot(range(11,42), concs, label=\"Visit concentration\")\n",
    "axes[0].set_xlabel(\"Week Number\")\n",
    "axes[0].set_ylabel(\"Visit concentration\")\n",
    "axes[0].set_title(\"Avg. visit concentration per week\")\n",
    "# plt.plot(dists, label=\"Distance from home\")\n",
    "axes[1].plot(range(11,42), dwells, label=\"Median dwell\")\n",
    "axes[1].set_xlabel(\"Week Number\")\n",
    "axes[1].set_ylabel(\"Median dwell (hrs)\")\n",
    "axes[1].set_title(\"Avg. median dwell per week\")\n",
    "\n",
    "plt.savefig('stats_viz.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing maps with 'folium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing datasets\n",
    "\n",
    "counts = pd.read_csv('counts.csv')\n",
    "df = pd.read_csv('df.csv').sort_values(by='poi_id')\n",
    "\n",
    "output = pd.read_csv(r'C:\\Users\\Ryzen\\Downloads\\IronHacks\\submission_prediction_output.csv')\n",
    "output = output.merge(df.drop(['week_number', 'raw_visit_counts', 'poi_cbg'], axis=1), how='left', on='poi_id').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "MAP_LAT=40.402\n",
    "MAP_LON=-86.902\n",
    "MAP_CENTER = (MAP_LAT, MAP_LON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data for heatmap animation\n",
    "# retrieving latitude, longitude, raw visit counts and week number from the dataset\n",
    "\n",
    "heat_data = []\n",
    "inds = []\n",
    "\n",
    "for week in df.week_number.unique():\n",
    "    temp = df[df.week_number == week]\n",
    "    data = []\n",
    "    for index, row in temp.iterrows():\n",
    "        data.append([row['latitude'], row['longitude'], row['raw_visit_counts']])\n",
    "        \n",
    "    heat_data.append(data)\n",
    "    inds.append('week ' + str(week))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data for percent change map\n",
    "# percent change = (visits in week 44 - visits in week 40) / (visits in week 40) * 100\n",
    "\n",
    "diff_data = []\n",
    "\n",
    "for poi in df.location_name.unique():\n",
    "    try:\n",
    "        temp = df[df.location_name == poi]\n",
    "        diff = temp[temp['week_number'] == 43]['raw_visit_counts'].values - temp[temp['week_number'] == 40]['raw_visit_counts'].values\n",
    "        diff = diff[0] / temp[temp['week_number'] == 40]['raw_visit_counts'] * 100\n",
    "        \n",
    "        diff_data.append([temp['latitude'].unique()[0], temp['longitude'].unique()[0], diff.values[0], poi])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data for prediction data map\n",
    "\n",
    "pred_data = []\n",
    "\n",
    "for poi in output.location_name.unique():\n",
    "    try:\n",
    "        temp = df[df.location_name == poi]\n",
    "        \n",
    "        pred_data.append([temp['latitude'].unique()[0], temp['longitude'].unique()[0], temp['raw_visit_counts'].unique()[0], poi])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating heatmap animation\n",
    "\n",
    "m = folium.Map(location=MAP_CENTER,\n",
    "                    zoom_start = 12, height='80%', width='80%')\n",
    "\n",
    "HeatMapWithTime(heat_data, index=inds, use_local_extrema=True, gradient={.3: 'blue', .66: 'lime', 1: 'red'}, radius=10).add_to(m)\n",
    "\n",
    "m.save('heatmap_animation.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating percent change map\n",
    "\n",
    "m1 = folium.Map(location=MAP_CENTER,\n",
    "                    zoom_start = 12, height='80%', width='80%')\n",
    "\n",
    "\n",
    "plugins.MarkerCluster(\n",
    "        locations=[[i[0], i[1]] for i in diff_data],\n",
    "        popups=[\"% change in {}: {:.2f}\".format(i[3], i[2]) for i in diff_data]).add_to(m1)\n",
    "\n",
    "m1.save(r'C:\\Users\\Ryzen\\Downloads\\IronHacks\\marker_cluster_diff.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating prediction values map\n",
    "\n",
    "m2 = folium.Map(location=MAP_CENTER,\n",
    "                    zoom_start = 12, height='80%', width='80%')\n",
    "\n",
    "\n",
    "plugins.MarkerCluster(\n",
    "        locations=[[i[0], i[1]] for i in pred_data],\n",
    "        popups=[\"Week 44 visits in {}: {}\".format(i[3], int(i[2])) for i in pred_data]).add_to(m2)\n",
    "\n",
    "m2.save(r'C:\\Users\\Ryzen\\Downloads\\IronHacks\\marker_cluster_predictions.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
